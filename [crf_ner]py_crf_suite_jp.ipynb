{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[crf-ner]py-crf-suite-jp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7ra/QmUKr9DESymYGtMlI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaeSeon/nlp-ner/blob/main/%5Bcrf_ner%5Dpy_crf_suite_jp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erfTJJdRTOXI",
        "outputId": "20dc2ddf-1650-447f-83c3-a899818e8279"
      },
      "source": [
        "!pip install python-crfsuite\n",
        "import nltk\n",
        "import pycrfsuite\n",
        "import warnings\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from itertools import chain"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-crfsuite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/47/58f16c46506139f17de4630dbcfb877ce41a6355a1bbf3c443edb9708429/python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
            "\r\u001b[K     |▍                               | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 21.5MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 12.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 8.2MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 7.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 7.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 143kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 153kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 174kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 184kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 194kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 204kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 215kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 225kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 235kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 245kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 266kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 276kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 286kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 296kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 307kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 317kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 337kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 348kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 358kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 368kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 378kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 389kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 399kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 409kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 430kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 440kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 450kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 460kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 471kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 481kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 491kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 501kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 512kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 522kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 532kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 542kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 552kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 563kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 573kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 583kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 593kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 604kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 614kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 624kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 634kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 645kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 655kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 665kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 675kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 686kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 696kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 706kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 716kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 727kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 737kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 747kB 7.2MB/s \n",
            "\u001b[?25hInstalling collected packages: python-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9LJS8OAWMxP"
      },
      "source": [
        "**DATA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Eh9YcgzV-cT"
      },
      "source": [
        "train_set = 'train_set.txt'\n",
        "test_set = 'test_set.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXYGM4x6WH40",
        "outputId": "4bc96029-a554-43e5-b60d-91e07d685da3"
      },
      "source": [
        "f = open(train_set)\n",
        "f.readlines()[:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1960\\tB-DATE\\n',\n",
              " '年代\\tI-DATE\\n',\n",
              " 'と\\tO\\n',\n",
              " '1970\\tB-DATE\\n',\n",
              " '年代\\tI-DATE\\n',\n",
              " 'の\\tO\\n',\n",
              " '間\\tO\\n',\n",
              " 'に\\tO\\n',\n",
              " '、\\tO\\n',\n",
              " 'ジョエル\\tB-PERSON\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sFXVVkbWRsl"
      },
      "source": [
        "def process_data(file_name):\n",
        "  sentence=[]\n",
        "  sentences=[]\n",
        "  with open (file_name,'r') as f:\n",
        "    for line in f.readlines():\n",
        "      if \"。\" in line and len(sentence)>0:\n",
        "        sentences.append(sentence)\n",
        "        sentence=[]\n",
        "      else:\n",
        "        if(len(line.split('\\t'))>1):\n",
        "          word=line.split('\\t')[0]\n",
        "          tag=line.split('\\t')[1]\n",
        "          sentence.append((word, tag))\n",
        "\n",
        "  return sentences"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXmy4Hb6aQyq"
      },
      "source": [
        "train_sents=process_data(train_set)\n",
        "test_sents=process_data(test_set)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdAJPcC0acx5",
        "outputId": "51ff7975-c176-4f74-bf14-3c24327907b9"
      },
      "source": [
        "train_sents[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1960', 'B-DATE\\n'),\n",
              " ('年代', 'I-DATE\\n'),\n",
              " ('と', 'O\\n'),\n",
              " ('1970', 'B-DATE\\n'),\n",
              " ('年代', 'I-DATE\\n'),\n",
              " ('の', 'O\\n'),\n",
              " ('間', 'O\\n'),\n",
              " ('に', 'O\\n'),\n",
              " ('、', 'O\\n'),\n",
              " ('ジョエル', 'B-PERSON\\n'),\n",
              " ('・', 'I-PERSON\\n'),\n",
              " ('モーゼス', 'I-PERSON\\n'),\n",
              " ('は', 'O\\n'),\n",
              " (' ', 'O\\n'),\n",
              " ('プログラム', 'O\\n'),\n",
              " ('中', 'O\\n'),\n",
              " ('で', 'O\\n'),\n",
              " ('積分', 'O\\n'),\n",
              " ('問題', 'O\\n'),\n",
              " ('で', 'O\\n'),\n",
              " ('の', 'O\\n'),\n",
              " ('記号', 'O\\n'),\n",
              " ('的', 'O\\n'),\n",
              " ('推論', 'O\\n'),\n",
              " ('の', 'O\\n'),\n",
              " ('パワー', 'O\\n'),\n",
              " ('を', 'O\\n'),\n",
              " ('示し', 'O\\n'),\n",
              " ('た', 'O\\n')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBp1ixrna-PH"
      },
      "source": [
        "**PyCRFSuite**\n",
        "\n",
        "1. 주어진 모든 feature를 다 가지고 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvfRgj0hay-W"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(), # word lower\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(), # word is upper?\n",
        "        'word.istitle=%s' % word.istitle(), # word is title?\n",
        "        'word.isdigit=%s' % word.isdigit(), # word is digit?\n",
        "        #'postag=' + postag,\n",
        "        #'postag[:2]=' + postag[:2],\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "            #'-1:postag=' + postag1,\n",
        "            #'-1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "    if i < len(sent) - 1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "            #'+1:postag=' + postag1,\n",
        "            #'+1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERpDLjbpbZ0c"
      },
      "source": [
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for  i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "    \n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7tG6010bbOn",
        "outputId": "d7625d64-9935-4f3c-92f5-55d77594c7a3"
      },
      "source": [
        "sent2features(train_sents[0])[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bias',\n",
              " 'word.lower=1960',\n",
              " 'word[-3:]=960',\n",
              " 'word[-2:]=60',\n",
              " 'word.isupper=False',\n",
              " 'word.istitle=False',\n",
              " 'word.isdigit=True',\n",
              " 'BOS',\n",
              " '+1:word.lower=年代',\n",
              " '+1:word.istitle=False',\n",
              " '+1:word.isupper=False']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU3xvHkgbk4q"
      },
      "source": [
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwmu-yyncdKE"
      },
      "source": [
        "# 모델에 데이터를 append하여 학습할 준비를 한다. \n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FRckFHsce8C"
      },
      "source": [
        "# 최소 다섯번 이상 등장한 feature만 이용\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True,\n",
        "    \n",
        "    # minimum frequency\n",
        "    'feature.minfreq': 5\n",
        "})"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKlSkFMtcjPJ"
      },
      "source": [
        "# 모델 학습\n",
        "model_name = 'jp.crfsuite'\n",
        "trainer.train(model_name)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bygAsfXQc6hX",
        "outputId": "4e7fe8f0-6f73-48a7-f4d1-45ac11a14158"
      },
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open(model_name)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f25adae0990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQvlu8ulc_CZ",
        "outputId": "a3e79c23-7e1f-4b6c-9c67-9efef1f569ae"
      },
      "source": [
        "# 테스트 문장에 대 ner tagging 수행\n",
        "example_sent = test_sents[0]\n",
        "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
        "\n",
        "print(\"Predicted:\", ', '.join(tagger.tag(sent2features(example_sent))))\n",
        "print(\"Correct:  \", ', '.join(sent2labels(example_sent)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "再 発行 の 際 に は 手数料 510 円 と 預り 金 500 円 の 合計 1 , 010 円 が 必要 で ある\n",
            "\n",
            "Predicted: O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", B-NUMBER\n",
            ", I-NUMBER\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", B-NUMBER\n",
            ", I-NUMBER\n",
            ", O\n",
            ", O\n",
            ", B-MONEY\n",
            ", I-MONEY\n",
            ", I-MONEY\n",
            ", I-MONEY\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            "\n",
            "Correct:   O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", B-MONEY\n",
            ", I-MONEY\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", B-MONEY\n",
            ", I-MONEY\n",
            ", O\n",
            ", O\n",
            ", B-MONEY\n",
            ", I-MONEY\n",
            ", I-MONEY\n",
            ", I-MONEY\n",
            ", O\n",
            ", O\n",
            ", O\n",
            ", O\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HitInQIdMMc"
      },
      "source": [
        "def bio_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Classification report for a list of BIO-encoded sequences.\n",
        "    It computes token-level metrics and discards \"O\" labels.\n",
        "    \n",
        "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
        "    to calculate averages properly!\n",
        "    \"\"\"\n",
        "    lb=preprocessing.LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "        \n",
        "    tagset = set(lb.classes_) - {'O'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "    \n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "    )"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1UjwS8fdWCU"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = []\n",
        "for sent in test_sents:\n",
        "    y_pred.append(tagger.tag(sent2features(sent)))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "IXaEESs5dYnM",
        "outputId": "c839d340-3415-40b9-ecd4-d043b130c42c"
      },
      "source": [
        "bio_classification_report(y_true, y_pred)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'                 precision    recall  f1-score   support\\n\\n    B-ARTIFACT\\n       0.65      0.32      0.43       169\\n    I-ARTIFACT\\n       0.64      0.38      0.48       320\\n        B-DATE\\n       0.95      0.87      0.91       305\\n        I-DATE\\n       0.94      0.93      0.93       470\\n       B-EVENT\\n       0.68      0.33      0.44        40\\n       I-EVENT\\n       0.58      0.40      0.47        86\\n    B-LOCATION\\n       0.85      0.48      0.61       588\\n    I-LOCATION\\n       0.71      0.38      0.49       318\\n       B-MONEY\\n       0.90      0.41      0.56        22\\n       I-MONEY\\n       1.00      0.60      0.75        40\\n      B-NUMBER\\n       0.76      0.71      0.73       203\\n      I-NUMBER\\n       0.72      0.71      0.71       252\\n             O\\n       0.92      0.99      0.95     23268\\nB-ORGANIZATION\\n       0.68      0.33      0.44       341\\nI-ORGANIZATION\\n       0.54      0.40      0.46       389\\n       B-OTHER\\n       0.76      0.44      0.56        84\\n       I-OTHER\\n       0.75      0.35      0.47       104\\n     B-PERCENT\\n       0.92      0.58      0.71        38\\n     I-PERCENT\\n       0.90      0.62      0.73        58\\n      B-PERSON\\n       0.62      0.11      0.19       295\\n      I-PERSON\\n       0.59      0.21      0.31       261\\n        B-TIME\\n       0.00      0.00      0.00         2\\n        I-TIME\\n       0.00      0.00      0.00        10\\n\\n      micro avg       0.91      0.91      0.91     27663\\n      macro avg       0.70      0.46      0.54     27663\\n   weighted avg       0.90      0.91      0.89     27663\\n    samples avg       0.91      0.91      0.91     27663\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ArTiJ0Wde8a"
      },
      "source": [
        "**한정된 feature만 가지고 학습**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQSdrQHWdlV-"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PErN7zNYdoQv"
      },
      "source": [
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, label in sent]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4asL1R8dyfR"
      },
      "source": [
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67thT7Ird0Q2"
      },
      "source": [
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yswv3ybd5_3"
      },
      "source": [
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True,\n",
        "    \n",
        "    # minimum frequency\n",
        "    'feature.minfreq': 5\n",
        "})"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXTLHS5UeF2v",
        "outputId": "86594693-e647-4240-ef53-05ffba244f3e"
      },
      "source": [
        "# 모델 학습\n",
        "model_name = 'jp_lower_features.crfsuite'\n",
        "trainer.train(model_name)\n",
        "tagger = pycrfsuite.Tagger() # 학습된 모델을 tagger로 불러옴\n",
        "tagger.open(model_name)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f25a9ed5c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHxYO33id8Bo"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = []\n",
        "for sent in test_sents:\n",
        "    y_pred.append(tagger.tag(sent2features(sent)))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "l4AjvckteNmQ",
        "outputId": "e9eae45e-f117-4f8a-906d-bf8279589be8"
      },
      "source": [
        "bio_classification_report(y_true, y_pred)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'                 precision    recall  f1-score   support\\n\\n    B-ARTIFACT\\n       0.65      0.33      0.43       169\\n    I-ARTIFACT\\n       0.49      0.42      0.45       320\\n        B-DATE\\n       0.94      0.86      0.90       305\\n        I-DATE\\n       0.91      0.91      0.91       470\\n       B-EVENT\\n       0.76      0.40      0.52        40\\n       I-EVENT\\n       0.71      0.51      0.59        86\\n    B-LOCATION\\n       0.84      0.48      0.61       588\\n    I-LOCATION\\n       0.73      0.39      0.51       318\\n       B-MONEY\\n       0.78      0.32      0.45        22\\n       I-MONEY\\n       0.95      0.47      0.63        40\\n      B-NUMBER\\n       0.77      0.62      0.68       203\\n      I-NUMBER\\n       0.72      0.62      0.67       252\\n             O\\n       0.92      0.98      0.95     23268\\nB-ORGANIZATION\\n       0.69      0.37      0.48       341\\nI-ORGANIZATION\\n       0.51      0.42      0.46       389\\n       B-OTHER\\n       0.71      0.38      0.50        84\\n       I-OTHER\\n       0.67      0.31      0.42       104\\n     B-PERCENT\\n       0.79      0.39      0.53        38\\n     I-PERCENT\\n       0.73      0.47      0.57        58\\n      B-PERSON\\n       0.57      0.09      0.16       295\\n      I-PERSON\\n       0.54      0.20      0.29       261\\n        B-TIME\\n       0.00      0.00      0.00         2\\n        I-TIME\\n       0.00      0.00      0.00        10\\n\\n      micro avg       0.90      0.90      0.90     27663\\n      macro avg       0.67      0.43      0.51     27663\\n   weighted avg       0.89      0.90      0.89     27663\\n    samples avg       0.90      0.90      0.90     27663\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDtHHR-QeRvI"
      },
      "source": [
        "**모델 확인**\n",
        "\n",
        "영향력이 높은 features와 각각에 해당하는 weight를 확인한다. \n",
        "\n",
        "모든 feature를 이용한 모델로 평가했다. \n",
        "\n",
        "Ner tagging에서 중요한 정보는 앞/뒤에 등장하는 단어이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "d1-tbd_EeUCE",
        "outputId": "ea997334-6a38-4ab0-a3c6-f6ec9f445fac"
      },
      "source": [
        "debugger = tagger.info()\n",
        "weights = debugger.state_features\n",
        "location_features = {feature:weight for feature, weight in weights.items() if 'LOCATION' in feature[1]}\n",
        "\n",
        "for feature, weight in sorted(location_features.items(), key=lambda x:-x[1])[:50]:\n",
        "    print('{} : {}'.format(feature, weight))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-19c3242baedf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdebugger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# weights = debugger.state_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# location_features = {feature:weight for feature, weight in weights.items() if 'LOCATION' in feature[1]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for feature, weight in sorted(location_features.items(), key=lambda x:-x[1])[:50]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Tagger.info\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.Tagger.info\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pycrfsuite/_dumpparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parse_%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_FILEHEADER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pycrfsuite/_dumpparser.py\u001b[0m in \u001b[0;36mparse_TRANSITIONS\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_TRANSITIONS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"\\(\\d+\\) (.+) --> (.+): ([+-]?\\d+\\.\\d+)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mfrom_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mfrom_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mto_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
          ]
        }
      ]
    }
  ]
}