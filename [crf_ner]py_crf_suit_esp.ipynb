{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[crf-ner]py-crf-suit-esp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJjKaeTkL8gM3I3+4jpXRF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaeSeon/nlp-ner/blob/main/%5Bcrf_ner%5Dpy_crf_suit_esp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWOW5sgQPoQT"
      },
      "source": [
        "# CRF(Conditional Random Field) based NER(Named Entity Recognition)\n",
        "\n",
        "**CRF**\n",
        "대표적인 sequential labeling인 품사판별을 생각해보자. \n",
        "\n",
        "* sequential labeling : 데이터의 형식이 벡터가 아닌 sequence인 sequential data에 대한 classification\n",
        "\n",
        "CRF는 앞, 뒤 단어와 품사 정보들을 이용한다. '너'라는 단어 앞, 뒤의 단어와 우리가 이미 예측한 앞의 품사를 이용해서 더욱 정확한 품사 판별을 한다. \n",
        "\n",
        "단어열의 길이가 n일 때 n번의 classification을 수행하지 않고 전체적인 문맥을 고려하여 한번의 classification을 수행함으로써 MEMM(Maximum Entropy Markov Model)의 문제였던 label bias를 해결한다.\n",
        "\n",
        "**potential function**\n",
        "\n",
        "n개의 단어열을 각각 high dimensional sparse vector 로 표현.\n",
        "\n",
        "일종의 Boolean filter처럼 작동한다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSCrheupKJNF",
        "outputId": "5f8e366d-8c3a-49d8-bdf2-bbd4a40dd6a7"
      },
      "source": [
        "!pip install python-crfsuite\n",
        "import nltk\n",
        "import pycrfsuite\n",
        "import warnings\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "from itertools import chain"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-crfsuite in /usr/local/lib/python3.7/dist-packages (0.9.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFMHrTm87hQ1",
        "outputId": "a08c0fc0-7d03-4317-fd51-4f131ad89e65"
      },
      "source": [
        "nltk.download('conll2002')\n",
        "# esp : 스페인어 데이터, ned : 네덜란드어 데이터\n",
        "print(nltk.corpus.conll2002.fileids())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2002 is already up-to-date!\n",
            "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUR4rF8fD_Jt"
      },
      "source": [
        "# (단어, 품사, NER tag)\n",
        "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
        "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbEll_YMEKoE",
        "outputId": "4431c813-8ddf-4cf6-d392-10c55e604eab"
      },
      "source": [
        "train_sents[0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Melbourne', 'NP', 'B-LOC'),\n",
              " ('(', 'Fpa', 'O'),\n",
              " ('Australia', 'NP', 'B-LOC'),\n",
              " (')', 'Fpt', 'O'),\n",
              " (',', 'Fc', 'O'),\n",
              " ('25', 'Z', 'O'),\n",
              " ('may', 'NC', 'O'),\n",
              " ('(', 'Fpa', 'O'),\n",
              " ('EFE', 'NC', 'B-ORG'),\n",
              " (')', 'Fpt', 'O'),\n",
              " ('.', 'Fp', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O280md3pEiDG"
      },
      "source": [
        "# **PyCRFSuite official tutorial**\n",
        "C++로 구현된 CRFsuite 를 파이썬 환경에서 이용할 수 있도록 해주는 라이브러리이다,\n",
        "CoNLL2002 dataset을 이용해 NER model을 학습할것이다. [official tutorial](https://github.com/scrapinghub/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb)\n",
        "\n",
        "이를 사용하기 위해서는 potential function을 디자인해야한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsU_6MhLL967"
      },
      "source": [
        "**1. 주어진 모든 feature를 다 가지고 학습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTuUSQba9nlF"
      },
      "source": [
        "# i 시점의 앞/뒤 단어인 i-1, i+1에 대하여 소문자화 한 각 단어 뒤의 2,3 글자, 단어의 품사 등을 이용\n",
        "# latin 계열 단어에서는 suffix가 유용한 힌트가 됨 \n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word.lower=' + word.lower(), \n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "        'word.isupper=%s' % word.isupper(),\n",
        "        'word.istitle=%s' % word.istitle(),\n",
        "        'word.isdigit=%s' % word.isdigit(),\n",
        "        'postag=' + postag,\n",
        "        'postag[:2]=' + postag[:2],\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "            '-1:word.istitle=%s' % word1.istitle(),\n",
        "            '-1:word.isupper=%s' % word1.isupper(),\n",
        "            '-1:postag=' + postag1,\n",
        "            '-1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "            '+1:word.istitle=%s' % word1.istitle(),\n",
        "            '+1:word.isupper=%s' % word1.isupper(),\n",
        "            '+1:postag=' + postag1,\n",
        "            '+1:postag[:2]=' + postag1[:2],\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN8XnMIN-bm7"
      },
      "source": [
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MO7en27-myb",
        "outputId": "be0a11d8-c565-4965-94aa-19a1bf5ea3c9"
      },
      "source": [
        "sent2features(train_sents[0])[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bias',\n",
              " 'word.lower=melbourne',\n",
              " 'word[-3:]=rne',\n",
              " 'word[-2:]=ne',\n",
              " 'word.isupper=False',\n",
              " 'word.istitle=True',\n",
              " 'word.isdigit=False',\n",
              " 'postag=NP',\n",
              " 'postag[:2]=NP',\n",
              " 'BOS',\n",
              " '+1:word.lower=(',\n",
              " '+1:word.istitle=False',\n",
              " '+1:word.isupper=False',\n",
              " '+1:postag=Fpa',\n",
              " '+1:postag[:2]=Fp']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHHlCbe-n-9"
      },
      "source": [
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKGqj2h_-qdN",
        "outputId": "fafcd5d9-d604-4e95-c9a1-d3a72d7512d7"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['bias', 'word.lower=melbourne', 'word[-3:]=rne', 'word[-2:]=ne', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=NP', 'postag[:2]=NP', 'BOS', '+1:word.lower=(', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fpa', '+1:postag[:2]=Fp'], ['bias', 'word.lower=(', 'word[-3:]=(', 'word[-2:]=(', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=Fpa', 'postag[:2]=Fp', '-1:word.lower=melbourne', '-1:word.istitle=True', '-1:word.isupper=False', '-1:postag=NP', '-1:postag[:2]=NP', '+1:word.lower=australia', '+1:word.istitle=True', '+1:word.isupper=False', '+1:postag=NP', '+1:postag[:2]=NP'], ['bias', 'word.lower=australia', 'word[-3:]=lia', 'word[-2:]=ia', 'word.isupper=False', 'word.istitle=True', 'word.isdigit=False', 'postag=NP', 'postag[:2]=NP', '-1:word.lower=(', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=Fpa', '-1:postag[:2]=Fp', '+1:word.lower=)', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fpt', '+1:postag[:2]=Fp'], ['bias', 'word.lower=)', 'word[-3:]=)', 'word[-2:]=)', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=Fpt', 'postag[:2]=Fp', '-1:word.lower=australia', '-1:word.istitle=True', '-1:word.isupper=False', '-1:postag=NP', '-1:postag[:2]=NP', '+1:word.lower=,', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fc', '+1:postag[:2]=Fc'], ['bias', 'word.lower=,', 'word[-3:]=,', 'word[-2:]=,', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=Fc', 'postag[:2]=Fc', '-1:word.lower=)', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=Fpt', '-1:postag[:2]=Fp', '+1:word.lower=25', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Z', '+1:postag[:2]=Z'], ['bias', 'word.lower=25', 'word[-3:]=25', 'word[-2:]=25', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=True', 'postag=Z', 'postag[:2]=Z', '-1:word.lower=,', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=Fc', '-1:postag[:2]=Fc', '+1:word.lower=may', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=NC', '+1:postag[:2]=NC'], ['bias', 'word.lower=may', 'word[-3:]=may', 'word[-2:]=ay', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=NC', 'postag[:2]=NC', '-1:word.lower=25', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=Z', '-1:postag[:2]=Z', '+1:word.lower=(', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fpa', '+1:postag[:2]=Fp'], ['bias', 'word.lower=(', 'word[-3:]=(', 'word[-2:]=(', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=Fpa', 'postag[:2]=Fp', '-1:word.lower=may', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=NC', '-1:postag[:2]=NC', '+1:word.lower=efe', '+1:word.istitle=False', '+1:word.isupper=True', '+1:postag=NC', '+1:postag[:2]=NC'], ['bias', 'word.lower=efe', 'word[-3:]=EFE', 'word[-2:]=FE', 'word.isupper=True', 'word.istitle=False', 'word.isdigit=False', 'postag=NC', 'postag[:2]=NC', '-1:word.lower=(', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=Fpa', '-1:postag[:2]=Fp', '+1:word.lower=)', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fpt', '+1:postag[:2]=Fp'], ['bias', 'word.lower=)', 'word[-3:]=)', 'word[-2:]=)', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=Fpt', 'postag[:2]=Fp', '-1:word.lower=efe', '-1:word.istitle=False', '-1:word.isupper=True', '-1:postag=NC', '-1:postag[:2]=NC', '+1:word.lower=.', '+1:word.istitle=False', '+1:word.isupper=False', '+1:postag=Fp', '+1:postag[:2]=Fp'], ['bias', 'word.lower=.', 'word[-3:]=.', 'word[-2:]=.', 'word.isupper=False', 'word.istitle=False', 'word.isdigit=False', 'postag=Fp', 'postag[:2]=Fp', '-1:word.lower=)', '-1:word.istitle=False', '-1:word.isupper=False', '-1:postag=Fpt', '-1:postag[:2]=Fp', 'EOS']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD-PNhP9lHb9"
      },
      "source": [
        "# 모델에 데이터를 append하여 학습할 준비를 한다. \n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAK26LHblta-"
      },
      "source": [
        "# 최소 다섯번 이상 등장한 feature만 이용\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True,\n",
        "    \n",
        "    # minimum frequency\n",
        "    'feature.minfreq': 5\n",
        "})"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOcbdIRvl1AU",
        "outputId": "bc2239c2-fe10-4296-b840-e556b531548c"
      },
      "source": [
        "trainer.train('conll2002-esp.crfsuite')\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('conll2002-esp.crfsuite')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f7c258b7c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf3jf9lBl4ks",
        "outputId": "68ae22dc-c1f1-4fe5-ecf5-531e32ffb4c4"
      },
      "source": [
        "example_sent = test_sents[0]\n",
        "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
        "\n",
        "print(\"Predicted:\", ', '.join(tagger.tag(sent2features(example_sent))))\n",
        "print(\"Correct:  \", ', '.join(sent2labels(example_sent)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La Coruña , 23 may ( EFECOM ) .\n",
            "\n",
            "Predicted: B-LOC, I-LOC, O, O, O, O, B-ORG, O, O\n",
            "Correct:   B-LOC, I-LOC, O, O, O, O, B-ORG, O, O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K21QbBtjl60k"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def bio_classification_report(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Classification report for a list of BIO-encoded sequences.\n",
        "    It computes token-level metrics and discards \"O\" labels.\n",
        "    \n",
        "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
        "    to calculate averages properly!\n",
        "    \"\"\"\n",
        "    lb=preprocessing.LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "        \n",
        "    tagset = set(lb.classes_) - {'O'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "    \n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "    )"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abYcCeTKmGQT"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = []\n",
        "for sent in test_sents:\n",
        "    y_pred.append(tagger.tag(sent2features(sent)))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "UtfrZXlKJ_YY",
        "outputId": "d9ae809f-29db-40ed-c5c9-62e05dcb4ebf"
      },
      "source": [
        "bio_classification_report(y_true, y_pred)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n       B-LOC       0.74      0.71      0.73      1084\\n       I-LOC       0.57      0.51      0.54       325\\n      B-MISC       0.61      0.37      0.46       339\\n      I-MISC       0.59      0.43      0.50       557\\n       B-ORG       0.76      0.78      0.77      1400\\n       I-ORG       0.78      0.76      0.77      1104\\n       B-PER       0.77      0.87      0.82       735\\n       I-PER       0.83      0.94      0.88       634\\n\\n   micro avg       0.75      0.72      0.73      6178\\n   macro avg       0.71      0.67      0.68      6178\\nweighted avg       0.74      0.72      0.73      6178\\n samples avg       0.09      0.09      0.09      6178\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNbRcU7cLMOS"
      },
      "source": [
        "**한정된 feature만 가지고 학습**\n",
        "\n",
        "bias, word lower, word[-3:], word[-2:]만 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLQhc5J4nwNU"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "    features = [\n",
        "        'bias',\n",
        "        'word[-3:]=' + word[-3:],\n",
        "        'word[-2:]=' + word[-2:],\n",
        "    ]\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.extend([\n",
        "            '-1:word.lower=' + word1.lower(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('BOS')\n",
        "        \n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.extend([\n",
        "            '+1:word.lower=' + word1.lower(),\n",
        "        ])\n",
        "    else:\n",
        "        features.append('EOS')\n",
        "                \n",
        "    return features"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5LvyEdXn74L"
      },
      "source": [
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2UhUMXLOYTu"
      },
      "source": [
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYMpzBcnObdZ"
      },
      "source": [
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF69OCqTOcrB"
      },
      "source": [
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': 50,  # stop earlier\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True,\n",
        "    \n",
        "    # minimum frequency\n",
        "    'feature.minfreq': 5\n",
        "})"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPVkJNoxOeOH",
        "outputId": "ba719e86-94d1-426d-b565-8d791792a3bc"
      },
      "source": [
        "trainer.train('conll2002-esp.crfsuite')\n",
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('conll2002-esp.crfsuite')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f7c2ddf7f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiYdngSiOgEa"
      },
      "source": [
        "y_true = y_test\n",
        "y_pred = []\n",
        "for sent in test_sents:\n",
        "    y_pred.append(tagger.tag(sent2features(sent)))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "SmGmQGjhOxAU",
        "outputId": "1d11b632-8172-4455-f7da-4efcfaa001ba"
      },
      "source": [
        "bio_classification_report(y_true, y_pred)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n       B-LOC       0.69      0.49      0.58      1084\\n       I-LOC       0.60      0.47      0.52       325\\n      B-MISC       0.52      0.20      0.29       339\\n      I-MISC       0.52      0.36      0.43       557\\n       B-ORG       0.74      0.55      0.63      1400\\n       I-ORG       0.71      0.52      0.60      1104\\n       B-PER       0.83      0.69      0.76       735\\n       I-PER       0.86      0.86      0.86       634\\n\\n   micro avg       0.72      0.54      0.62      6178\\n   macro avg       0.68      0.52      0.58      6178\\nweighted avg       0.71      0.54      0.61      6178\\n samples avg       0.07      0.07      0.07      6178\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maFkbw-iO33S"
      },
      "source": [
        "**모델 확인**\n",
        "\n",
        "영향력이 높은 features와 각각에 해당하는 weight를 확인한다. \n",
        "\n",
        "모든 feature를 이용한 모델로 평가했다. \n",
        "\n",
        "Ner tagging에서 중요한 정보는 앞/뒤에 등장하는 단어이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeveGZ8cO2Z7",
        "outputId": "41eb9205-68d2-461c-f9c8-4f260b373b2e"
      },
      "source": [
        "debugger = tagger.info()\n",
        "weights = debugger.state_features\n",
        "location_features = {feature:weight for feature, weight in weights.items() if 'LOC' in feature[1]}\n",
        "\n",
        "for feature, weight in sorted(location_features.items(), key=lambda x:-x[1])[:50]:\n",
        "    print('{} : {}'.format(feature, weight))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('-1:word.lower=despejado', 'B-LOC') : 6.919385\n",
            "('-1:word.lower=efe-cantabria', 'B-LOC') : 6.274558\n",
            "('word[-3:]=yun', 'B-LOC') : 5.874011\n",
            "('-1:word.lower=palacio', 'I-LOC') : 5.86573\n",
            "('-1:word.lower=puente', 'I-LOC') : 5.553516\n",
            "('-1:word.lower=costa', 'I-LOC') : 5.458388\n",
            "('-1:word.lower=avenida', 'I-LOC') : 5.372484\n",
            "('word[-3:]=nón', 'B-LOC') : 5.322154\n",
            "('word[-3:]=iés', 'B-LOC') : 5.147951\n",
            "('-1:word.lower=nuboso', 'B-LOC') : 5.10912\n",
            "('word[-3:]=ael', 'B-LOC') : 4.857369\n",
            "('-1:word.lower=cantabria', 'B-LOC') : 4.785114\n",
            "('-1:word.lower=santa', 'I-LOC') : 4.763376\n",
            "('-1:word.lower=parque', 'I-LOC') : 4.587954\n",
            "('word[-3:]=kio', 'B-LOC') : 4.379538\n",
            "('+1:word.lower=cairo', 'B-LOC') : 4.342166\n",
            "('+1:word.lower=coruña', 'B-LOC') : 4.315112\n",
            "('+1:word.lower=unido', 'B-LOC') : 3.890058\n",
            "('word[-3:]=lmo', 'B-LOC') : 3.739574\n",
            "('-1:word.lower=paseo', 'I-LOC') : 3.709889\n",
            "('-1:word.lower=bulevar', 'I-LOC') : 3.681638\n",
            "('-1:word.lower=lluvioso', 'B-LOC') : 3.674013\n",
            "('word[-3:]=uay', 'B-LOC') : 3.642079\n",
            "('word[-3:]=cón', 'B-LOC') : 3.596598\n",
            "('-1:word.lower=en', 'B-LOC') : 3.543269\n",
            "('+1:word.lower=24', 'B-LOC') : 3.542004\n",
            "('-1:word.lower=hacia', 'B-LOC') : 3.536268\n",
            "('word[-3:]=ami', 'B-LOC') : 3.509685\n",
            "('+1:word.lower=salvador', 'B-LOC') : 3.479515\n",
            "('word[-3:]=jón', 'B-LOC') : 3.455784\n",
            "('word[-3:]=lén', 'B-LOC') : 3.42167\n",
            "('-1:word.lower=oriente', 'I-LOC') : 3.322408\n",
            "('word[-3:]=joz', 'B-LOC') : 3.193083\n",
            "('word[-3:]=rís', 'B-LOC') : 3.173117\n",
            "('-1:word.lower=barrio', 'I-LOC') : 3.164656\n",
            "('word[-3:]=gón', 'B-LOC') : 3.154478\n",
            "('word[-3:]=otá', 'B-LOC') : 3.150019\n",
            "('-1:word.lower=9', 'B-LOC') : 3.140451\n",
            "('word[-3:]=dua', 'B-LOC') : 3.104703\n",
            "('word[-3:]=RFA', 'B-LOC') : 3.09722\n",
            "('word[-3:]=ovo', 'B-LOC') : 3.078659\n",
            "('-1:word.lower=calle', 'I-LOC') : 3.062484\n",
            "('+1:word.lower=26', 'B-LOC') : 3.007361\n",
            "('-1:word.lower=desde', 'B-LOC') : 3.000968\n",
            "('+1:word.lower=25', 'B-LOC') : 2.997031\n",
            "('-1:word.lower=campo', 'I-LOC') : 2.987284\n",
            "('-1:word.lower=12', 'B-LOC') : 2.940425\n",
            "('word[-3:]=ney', 'B-LOC') : 2.935831\n",
            "('-1:word.lower=plaza', 'I-LOC') : 2.934359\n",
            "('word[-3:]=uta', 'B-LOC') : 2.914302\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}